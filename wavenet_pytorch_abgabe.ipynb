{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wavenet_pytorch_abgabe.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lgrC_LLO8ZQv",
        "GJH6nhriHdkr",
        "4pGgzGNc-L9f",
        "Ze4PvQNR-eow"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8AlT81n8CAG",
        "colab_type": "text"
      },
      "source": [
        "# Wavenet Implementation with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgrC_LLO8ZQv",
        "colab_type": "text"
      },
      "source": [
        "## Preparation of the Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6EnxWNKsGeX",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title If you want to mount your Google Drive, you should do it here by commenting in the following Code\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BGUwJjMO6vT",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Cloning of the important Script from GitHub\n",
        "!git clone https://github.com/vincentherrmann/pytorch-wavenet.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_hRJUSRPKNz",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Navigating to the Script that was just downloaded\n",
        "%cd /content/pytorch-wavenet/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YJbJZfSPU8E",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Version 0.3.0 of PyTorch is required. Therefore it needs to be downloaded and installed.\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI6D8lQ4PXCW",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# @title Tensorflow version 1.12.0 is required. This version is downloaded and installed here.\n",
        "\n",
        "\n",
        "!pip install tensorflow==1.12.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJH6nhriHdkr",
        "colab_type": "text"
      },
      "source": [
        "##The next four blocks of code activate the Tensorboard, on which you can get with the help of the created link.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl3lxiD8Pa9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0afUsjtdPdBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = 'logs/chaconne_model'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMujpom4PfV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK_-oyB1Ph45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pGgzGNc-L9f",
        "colab_type": "text"
      },
      "source": [
        "##Code for the Training and Generating of the WaveNet model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCei74OIPjX2",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title First all necessary packages are getting imported\n",
        "import torch\n",
        "from wavenet_model import *\n",
        "from audio_data import WavenetDataset\n",
        "from wavenet_training import *\n",
        "from model_logging import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkyb5z5YS_1w",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# @title then, the data type and the label are getting initialized on cuda if a gpu is available.\n",
        "# initialize cuda option\n",
        "dtype = torch.FloatTensor # data type\n",
        "ltype = torch.LongTensor # label type\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    print('use gpu')\n",
        "    dtype = torch.cuda.FloatTensor\n",
        "    ltype = torch.cuda.LongTensor\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "else: \n",
        "    print('gpu not available')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDJ5j-K5TIb2",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Here the acutal Neural Network is created.\n",
        "model = WaveNetModel(layers=10,\n",
        "                     blocks=3,\n",
        "                     dilation_channels=32,\n",
        "                     residual_channels=32,\n",
        "                     skip_channels=1024,\n",
        "                     end_channels=512, \n",
        "                     output_length=16,\n",
        "                     dtype=dtype, \n",
        "                     bias=True)\n",
        "#model = load_latest_model_from('snapshots', use_cuda=use_cuda)\n",
        "\n",
        "#model = model.cuda()\n",
        "\n",
        "print('model: ', model)\n",
        "print('receptive field: ', model.receptive_field)\n",
        "print('parameter count: ', model.parameter_count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze4PvQNR-eow",
        "colab_type": "text"
      },
      "source": [
        "###Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38EHnhTRTPdz",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title In this Codeblock, the Trainingdata is getting initialized. Therefore the Trainingdata needs to be in the path train_samples/bach_chaconne. In this Implementation, there is already a dataset.npz file, with audio-data of a violin. If you want to use other data, you need to remove the dataset.npz file. You can then put some audio files that you like to train the model on in this path. The Code then transforms these files into the dataset.npz file. This file is used by the Model in the end.\n",
        "data = WavenetDataset(dataset_file='train_samples/bach_chaconne/dataset.npz',\n",
        "                      item_length=model.receptive_field + model.output_length - 1,\n",
        "                      target_length=model.output_length,\n",
        "                      file_location='train_samples/bach_chaconne',\n",
        "                      test_stride=500)\n",
        "print('the dataset has ' + str(len(data)) + ' items')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARozJb6YTZAv",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title As long as the Tensorboardlogger is used, this function is used as logging function. Also it should give some intermediate results.\n",
        "def generate_and_log_samples(step):\n",
        "    sample_length=32000\n",
        "\n",
        "\n",
        "    gen_model = load_latest_model_from('snapshots', use_cuda=False)\n",
        "   \n",
        "    print(\"start generating...\")\n",
        "    samples = generate_audio(gen_model,\n",
        "                             length=sample_length,\n",
        "                             temperatures=[0.5])\n",
        "    tf_samples = tf.convert_to_tensor(samples, dtype=tf.float32)\n",
        "    logger.audio_summary('temperature_0.5', tf_samples, step, sr=16000)\n",
        "\n",
        "    samples = generate_audio(gen_model,\n",
        "                             length=sample_length,\n",
        "                             temperatures=[1.])\n",
        "    tf_samples = tf.convert_to_tensor(samples, dtype=tf.float32)\n",
        "    logger.audio_summary('temperature_1.0', tf_samples, step, sr=16000)\n",
        "    print(\"audio clips generated\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K118hGKTfk-",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title One can either use the Tensorboardlogger , with which you can follow your trainingdata on Tensorboard or one can use a simple Logger, where the logging-data is displayed directly on the console.\n",
        "logger = TensorboardLogger(log_interval=200,\n",
        "                           validation_interval=400,\n",
        "                           generate_interval=1000,\n",
        "                           generate_function=generate_and_log_samples,\n",
        "                           log_dir=\"logs/chaconne_model\")\n",
        "\n",
        "#logger = Logger(log_interval=200,\n",
        "#                validation_interval=400,\n",
        "#                generate_interval=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54HyQYniTjxR",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title In the following Codeblock, the WaveNet model is trainied. Therefore a trainer is created. This trainier is getting the batch_size and the number of epochs as parameters.\n",
        "trainer = WavenetTrainer(model=model.cuda(),\n",
        "                         dataset=data,\n",
        "                         lr=0.001,\n",
        "                         snapshot_path='snapshots',\n",
        "                         snapshot_name='chaconne_model',\n",
        "                         snapshot_interval=1000,\n",
        "                         logger=logger,\n",
        "                         dtype=dtype,\n",
        "                         ltype=ltype)\n",
        "\n",
        "\n",
        "print('start training...')\n",
        "trainer.train(batch_size=6,\n",
        "              epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP3qFR1p-hYK",
        "colab_type": "text"
      },
      "source": [
        "###Generating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th4ZUMu_Pk0w",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title In this Codeblock, an output is created. This is happening on the basis of the trained model. The length of the created output can be varied with the variable num_samples. 16000 Samples are one second of output. The rate is responsible for the playing-speed of the ouptut.\n",
        "start_data = data[250000][0] # use start data from the data set\n",
        "start_data = torch.max(start_data, 0)[1] # convert one hot vectors to integers\n",
        "\n",
        "def prog_callback(step, total_steps):\n",
        "    print(str(100 * step // total_steps) + \"% generated\")\n",
        "\n",
        "model.cpu()\n",
        "generated = model.generate_fast(num_samples=160000,\n",
        "                                 first_samples=start_data,\n",
        "                                 progress_callback=prog_callback,\n",
        "                                 progress_interval=1000,\n",
        "                                 temperature=1.0,\n",
        "                                 regularize=0.)\n",
        "\n",
        "\n",
        "import IPython.display as ipd\n",
        "\n",
        "ipd.Audio(generated, rate=16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwPCkbgxrmwG",
        "colab_type": "text"
      },
      "source": [
        "##Sources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJVFF6QMrq2P",
        "colab_type": "text"
      },
      "source": [
        "[Deep Minds Blog Article about WaveNet](https://deepmind.com/blog/article/wavenet-generative-model-raw-audio)\n",
        "\n",
        "[WaveNet Paper](https://arxiv.org/pdf/1609.03499.pdf)\n",
        "\n",
        "[Github tensorflow WaveNet Project](https://github.com/ibab/tensorflow-wavenet)\n",
        "\n",
        "[Google Assistants Voice Synthesizer, overview of WaveNet](https://towardsdatascience.com/wavenet-google-assistants-voice-synthesizer-a168e9af13b1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr1P94wPsspr",
        "colab_type": "text"
      },
      "source": [
        "There is another Jupyter Notebook in the respository, which was realized with tensorflow. With this Notebook you can train the WaveNet on voice"
      ]
    }
  ]
}