{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wavenet",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonasZimmer1994/deeplearning_wavenet/blob/master/wavenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTgQmU9ElLn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjbVAVOD2yEd",
        "colab_type": "code",
        "outputId": "82ddcfad-447c-4971-e584-998f53376dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/pytorch-wavenet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/pytorch-wavenet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjtIfbAJr7Tm",
        "colab_type": "code",
        "outputId": "0039881c-58f4-49d7-d6c4-70a501df45eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.0.post4\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
            "\u001b[K     |████████████████████████████████| 592.3MB 96.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.17.4)\n",
            "\u001b[31mERROR: torchvision 0.4.2 has requirement torch==1.3.1, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.59 has requirement torch>=1.0.0, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.3.1\n",
            "    Uninstalling torch-1.3.1:\n",
            "      Successfully uninstalled torch-1.3.1\n",
            "Successfully installed torch-0.3.0.post4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGsXBTVJJsH-",
        "colab_type": "code",
        "outputId": "a87dc4be-0288-48c2-bcb6-a0c65fa88931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        }
      },
      "source": [
        "!pip install tensorflow==1.12.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 115kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.33.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.15.0)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.17.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (42.0.2)\n",
            "Installing collected packages: tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHM-oZO84BDb",
        "colab_type": "code",
        "outputId": "b0540784-e545-47b9-9308-04d53a4b1a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-17 17:23:10--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 35.168.165.30, 34.206.134.194, 3.229.196.117, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|35.168.165.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  16.6MB/s    in 0.8s    \n",
            "\n",
            "2019-12-17 17:23:11 (16.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: j\n",
            "error:  invalid response [j]\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPrdOrCa4RXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = 'logs/chaconne_model'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAKuynuR4eX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_i5fVlQ4hNN",
        "colab_type": "code",
        "outputId": "ae6ba38b-3c22-4f34-e557-c57bf9bdd0d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://c1ba38fa.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7fTDMJi4cff",
        "colab_type": "code",
        "outputId": "0cb04495-0e12-415f-d70d-ece3f85e134e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train_script.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "use gpu\n",
            "move model to gpu\n",
            "model:  WaveNetModel(\n",
            "  (filter_convs): ModuleList(\n",
            "    (0): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (1): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (3): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (4): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (5): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (6): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (7): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (8): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (9): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (10): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (11): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (12): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (13): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (14): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (15): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (16): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (17): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (18): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (19): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (20): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (21): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (22): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (23): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (24): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (25): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (26): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (27): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (28): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (29): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "  )\n",
            "  (gate_convs): ModuleList(\n",
            "    (0): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (1): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (3): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (4): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (5): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (6): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (7): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (8): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (9): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (10): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (11): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (12): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (13): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (14): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (15): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (16): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (17): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (18): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (19): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (20): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (21): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (22): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (23): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (24): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (25): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (26): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (27): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (28): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (29): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "  )\n",
            "  (residual_convs): ModuleList(\n",
            "    (0): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (2): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (3): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (4): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (5): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (6): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (7): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (8): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (9): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (10): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (11): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (12): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (13): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (14): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (15): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (16): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (17): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (18): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (19): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (20): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (21): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (22): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (23): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (24): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (25): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (26): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (27): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (28): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (29): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "  )\n",
            "  (skip_convs): ModuleList(\n",
            "    (0): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (2): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (3): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (4): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (5): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (6): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (7): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (8): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (9): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (10): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (11): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (12): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (13): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (14): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (15): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (16): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (17): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (18): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (19): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (20): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (21): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (22): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (23): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (24): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (25): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (26): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (27): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (28): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (29): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "  )\n",
            "  (start_conv): Conv1d (256, 32, kernel_size=(1,), stride=(1,))\n",
            "  (end_conv_1): Conv1d (1024, 512, kernel_size=(1,), stride=(1,))\n",
            "  (end_conv_2): Conv1d (512, 256, kernel_size=(1,), stride=(1,))\n",
            ")\n",
            "receptive field:  3070\n",
            "parameter count:  1834592\n",
            "one hot input\n",
            "the dataset has 598277 items\n",
            "start training...\n",
            "epoch 0\n",
            "one training step does take approximately 0.7976271986961365 seconds)\n",
            "Process Process-8:\n",
            "Process Process-6:\n",
            "Process Process-5:\n",
            "Traceback (most recent call last):\n",
            "  File \"train_script.py\", line 84, in <module>\n",
            "Process Process-4:\n",
            "Process Process-1:\n",
            "Process Process-3:\n",
            "Process Process-7:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
            "    r = index_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
            "    r = index_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
            "    r = index_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
            "    r = index_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
            "    r = index_queue.get()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
            "    r = index_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
            "    r = index_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "Process Process-2:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
            "    r = index_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/content/drive/My Drive/pytorch-wavenet/wavenet_training.py\", line 76, in train\n",
            "    self.optimizer.step()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\", line 70, in step\n",
            "    exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZoFlx8UrpbU",
        "colab_type": "code",
        "outputId": "989991cf-f867-4d55-f236-7decdb36da93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python generate_script.py\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "load model snapshots/chaconne_model_2019-12-17_16-21-16\n",
            "model:  WaveNetModel(\n",
            "  (filter_convs): ModuleList(\n",
            "    (0): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (1): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (3): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (4): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (5): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (6): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (7): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (8): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (9): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (10): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (11): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (12): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (13): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (14): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "  )\n",
            "  (gate_convs): ModuleList(\n",
            "    (0): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (1): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (3): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (4): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (5): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (6): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (7): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (8): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (9): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (10): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (11): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (12): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (13): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "    (14): Conv1d (32, 32, kernel_size=(2,), stride=(1,))\n",
            "  )\n",
            "  (residual_convs): ModuleList(\n",
            "    (0): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (2): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (3): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (4): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (5): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (6): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (7): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (8): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (9): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (10): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (11): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (12): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (13): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "    (14): Conv1d (32, 32, kernel_size=(1,), stride=(1,))\n",
            "  )\n",
            "  (skip_convs): ModuleList(\n",
            "    (0): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (2): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (3): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (4): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (5): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (6): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (7): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (8): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (9): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (10): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (11): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (12): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (13): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (14): Conv1d (32, 1024, kernel_size=(1,), stride=(1,))\n",
            "  )\n",
            "  (start_conv): Conv1d (256, 32, kernel_size=(1,), stride=(1,))\n",
            "  (end_conv_1): Conv1d (1024, 512, kernel_size=(1,), stride=(1,))\n",
            "  (end_conv_2): Conv1d (512, 256, kernel_size=(1,), stride=(1,))\n",
            ")\n",
            "receptive field:  94\n",
            "parameter count:  1249472\n",
            "one hot input\n",
            "the dataset has 569678 items\n",
            "0% generated\n",
            "one generating step does take approximately 0.003933780193328858 seconds)\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "0% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "1% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "2% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "3% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "4% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "5% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "6% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "7% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "8% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "9% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "10% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "11% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "12% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "13% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "14% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "15% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "16% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "17% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "18% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "19% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "20% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "21% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "22% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "23% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "24% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "25% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "26% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "27% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "28% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "29% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "30% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "31% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "32% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "33% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "34% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "35% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "36% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "37% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "38% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "39% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "40% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "41% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "42% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "43% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "44% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "45% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "46% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "47% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "48% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "49% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "50% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "51% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "52% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "53% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "54% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "55% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "56% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "57% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "58% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "59% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "60% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "61% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "62% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "63% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "64% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "65% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "66% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "67% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "68% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "69% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "70% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "71% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "72% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "73% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "74% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "75% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "76% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "77% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "78% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "79% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "80% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "81% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "82% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "83% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "84% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "85% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "86% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "87% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "88% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "89% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "90% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "91% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "92% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "93% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "94% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "95% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "96% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "97% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "98% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "99% generated\n",
            "[ 0.10611724  0.13880265  0.14512545 ...  0.05351483 -0.00982659\n",
            " -0.1109919 ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}